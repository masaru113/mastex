\documentclass[uplatex,a4j,12pt,dvipdfmx]{jsarticle}
\usepackage{amsmath,amsthm,amssymb,bm,color,enumitem,mathrsfs,url,epic,eepic,ascmac,ulem,here,ascmac}
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage[english]{babel}
\usepackage[dvipdfm]{graphicx}
\usepackage[hypertex]{hyperref}

\title{$\alpha$ エラーと $\beta$ エラーに関する読書ノート}
\author{岡田 大 (Okada Masaru)}
\date{\today}

\begin{document}

\maketitle

\section{統計的有意性の概念とその実用性}
統計的な議論において「\textbf{有意である}」という表現は、単なる数値的な差の大小とは異なる、非常に重要な意味を持ちます。例えば、大企業においてある施策が年間でわずか1円の売上増加要因になったとしても、実務的な観点からはその情報はほとんど無意味かもしれません。しかし、その極めて微小で「意味が感じられない差」であっても、それが\textbf{偶然のデータのばらつき}（ランダムなノイズ）によって生じたとは考えにくい、という客観的な根拠がある場合に、統計学ではその差を「有意」であると表現します。

\subsection{統計的有意性と実務的な重要性}
典型的には、二つのグループ、例えば新しいマーケティング手法を試したグループと従来の手法を用いたグループの間には、平均値や割合などの代表値に何らかの差が生じます。これはデータのばらつきがある以上、自然なことです。しかし、その差が例えばデータの標準偏差の2つ分（$\pm 2SD$）以上に及ぶような\textbf{大きなもの}である場合、それは単なる偶然ではなく、背後に何らかの系統的な要因、すなわち「意味のある違い」が存在すると考えるのが妥当であるとされます。この基準が統計的有意性の判断の一つの目安となります。しかしながら、この概念の真髄は、差の\textbf{大きさ}よりも、その差が\textbf{偶然によるものと見なせる確率の低さ}にあるのです。私たちが知りたいのは、見つけた差が「たまたま」ではなく、再現性のある「本質的な違い」であるかどうかです。

\section{検出力の重要性と現実的な課題}
実社会のデータ分析においては、比較するグループ間で平均値が標準偏差の2つ分も大きく乖離していることは稀です。もしそれほど大きな差があるならば、専門的な統計分析を用いずとも、その違いは\textbf{直感的に明らか}であるでしょう。したがって、統計学の真の課題は、標準偏差2つ分よりは小さいけれども、実務的な意味を持つ\textbf{現実的な差}を、\textbf{最小限のデータ}から、いかに見つけることができるかという点にあります。この能力を統計学では「\textbf{検出力 (Statistical Power)}」と呼びます。

\subsection{検出力の定義と最大化の難しさ}
検出力とは、簡単に言えば「\textbf{真実に差が存在している}という仮説が正しいときに、統計的検定によって\textbf{きちんと有意差としてその事実を検出できる確率}」を指します。この検出力を高めることが、研究やビジネスにおける意思決定の精度を高める鍵となります。しかしながら、検出力を最大化すれば全てが解決するわけではありません。極端な話、「思いついたことは全て、何の根拠データにも基づかず無責任に主張し続ける」という方法を取れば、もしその仮説が正しかった場合には100\%意味のある差を見つけられたことになります。これは一見、検出力が最大化されているように見えますが、同時に多くの間違った主張を生み出す、\textbf{有害なアプローチ}です。世の中には、根拠に基づかない思いつきをもっともらしく主張する人々がいますが、彼らの行動は、ある意味で検出力のみを最大化しようとする極端な例と見なせます。彼らは常に何らかの「危機」や「成功」を予測し続けることで、結果的に「壊れた時計が1日2度だけ正しい時刻を指す」ように、たまたま予測が的中する瞬間を作り出します。

\section{$\alpha$ エラーと $\beta$ エラー：誤りの類型}
検出力のみを最大化するアプローチが有害であるのは、「正しい仮説を見逃してしまう」誤り、すなわち$\beta$エラーのリスクのみを考慮し、その逆の誤り、つまり「\textbf{間違った仮説を正しいとしてしまう}」リスクを無視しているからです。統計学における誤りには二種類が存在します。

\subsection{第一種の過誤 ($\alpha$ エラー)}
何の差も無いにもかかわらず、\textbf{「差がある」と誤って主張してしまう}誤りのことを「\textbf{$\alpha$エラー}（第一種の過誤）」と呼びます。これは、真実が「差がない」という帰無仮説のもとで、それを棄却してしまう誤りであり、一般に「あわて者の過ち (\textbf{a}larmist's error)」とも表現されます。無根拠な主張を垂れ流す人々は、この$\alpha$エラーを犯すリスクを顧みず、とにかく何かを主張することでぼんやり者の過ち（$\beta$エラー）をゼロにしようと焦っていると言えるでしょう。

\subsection{第二種の過誤 ($\beta$ エラー)}
一方で、\textbf{本当は差がある}（真の仮説が正しい）にもかかわらず、\textbf{それを見逃してしまう}誤りのことを「\textbf{$\beta$エラー}（第二種の過誤）」と呼びます。これは、真実が「差がある」という対立仮説のもとで、帰無仮説を棄却しない誤りであり、一般に「ぼんやり者の過ち (\textbf{b}lockhead's error)」と称されます。この誤りをゼロにしようとする極端な例が、「誰が何を主張しようとも、厳密には分からないから永遠に慎重に議論しよう」と主張し、一切の行動や仮説形成を避ける人々です。彼らは$\alpha$エラーのリスクはゼロにできますが、目前の真実さえもぼんやりと見逃し続けることになります。しかし、現実の意思決定の多くは時間との勝負であり、医師が患者を慎重に見続けるだけで治療を始めなければ、刻々と損失（あるいは命）が失われていくように、ぼんやり者でいることにも大きな代償が伴います。

\section{有意水準の設定とトレードオフの関係}
$\alpha$エラー（あわて者の過ち）と$\beta$エラー（ぼんやり者の過ち）は、基本的に\textbf{トレードオフ}の関係にあります。データのばらつきという不確実な事象を扱う以上、両方の過ちを同時に完全にゼロにすることは不可能です。統計学では、この二つの過ちの間で、いかに現実的かつ合理的な判断を下すかということが定式化されています。

\subsection{最適な意思決定のためのフレームワーク}
そのための第一歩として、統計学ではまず\textbf{$\alpha$エラーの許容範囲}を明確に決定します。この許容範囲のことを「\textbf{有意水準} ($\alpha$ level)」と呼びます。通常、この水準は$5\%$や$1\%$などに設定されます。これは、「本当は差がないのに、誤って差があると判断してしまう確率を最大でこの水準に抑えます」という、研究者や実務家があらかじめ設定する\textbf{リスクの閾値}です。この有意水準という$\alpha$エラーの制約（上限）を設けた上で、次に$\beta$エラーを最小化すること、すなわち\textbf{検出力を最大化}することを目指します。

\section{統計的検定と最強力検定}
統計的検定とは、ある特定の\textbf{仮説が正しいと考えられるかどうかを判断するための手法}全体を指す一般的な名称です。

\subsection{検定手法の選択と検出力}
単純に分析に用いる\textbf{データの量（サンプルサイズ）を増やす}ほど、検出力は増し、真実を見逃すリスクは減少します。しかし、実務ではデータ数が限られていることが多いため、限られたデータ数でも真実をぼんやり見逃してしまわないよう、\textbf{仮説やデータの種類に応じて最適な検定手法を使い分ける}ことが極めて重要となります。例えば、平均値の差を比較するなら$t$検定、割合の差なら$\chi^2$検定などが選択肢となります。さらに統計学には、事前に想定した\textbf{有意水準}という制約（$\alpha$エラーの上限）のもとで、\textbf{最も検出力が高い}ことが理論的に証明されている検定手法が存在します。これを「\textbf{最強力検定 (Most Powerful Test)}」と呼びます。

\section{マーケティングにおける検定の実例}
統計的検定の概念は、特にA/Bテストのような\textbf{マーケティング施策の評価}で日常的に用いられています。例えば、ウェブサイトの新しいデザインを導入した結果、コンバージョン率が$0.10\%$から$0.11\%$にわずか$0.01\%$上昇したとします。この$0.01\%$の差は非常に小さいですが、もしこれが真に意味のある差（本質的な優位性）であれば、サービスの売上を長期的に$1.1$倍に押し上げる可能性があります。逆に、この$0.01\%$の差が単なる\textbf{偶然の変動}によるものであった場合、その後のデザインの変更やシステム改修は全て無駄なコストとなり、企業は「ただの偶然」を追いかける堂々巡りに陥ってしまいます。この\textbf{わずか$0.01\%$の差を「統計的に有意な差」と判断すべきか}、それとも「偶然による統計的に意味のない差」として棄却すべきかを判断する際に用いられるのが、統計的検定のフレームワークなのです。検定は、この意思決定におけるリスク（$\alpha$エラーと$\beta$エラー）を定量的に管理し、最も合理的な判断を下すための客観的な手法を提供します。

\section{普遍的な理論・コンセプト}
統計的有意性, データのばらつき, 標準偏差, 検出力, $\alpha$エラー, $\beta$エラー, 帰無仮説, 対立仮説, 有意水準, 統計的検定, 最強力検定, $t$検定, $\chi^2$検定, トレードオフ

\subsection{理解度確認クイズ}

\begin{enumerate}
	\item 統計的検定において、真実は「差がない」にもかかわらず、誤って「差がある」と結論づけてしまう過誤は何と呼ばれますか。
	\item 統計的検定において、本当は「差がある」にもかかわらず、その差を見逃してしまい、「差がない」と結論づけてしまう過誤は何と呼ばれますか。
	\item 真実に差が存在する場合に、それを正しく検出できる確率として定義される統計学上の指標は何ですか。
	\item 誤って差があると結論づけてしまう過誤の発生確率の許容上限として、研究者が事前に設定するリスクの閾値は何ですか。
	\item 統計的検定の基本的な枠組みにおいて、まずその「真実性」を疑って検証の対象とする仮説は何ですか。
	\item データ分析において、見出された差が偶然のデータの変動によって生じたものではないと判断される状態を、統計学では何と呼びますか。
	\item 「あわて者の過ち」というニックネームで呼ばれる過誤は、統計学上の専門用語で何ですか。
	\item 統計的検定において、あらかじめ定めたリスク水準の制約のもとで、最も高い検出力を実現する検定手法は何と称されますか。
	\item 統計学において、データのばらつきの度合いを示す代表的な指標の一つで、平均値からの散らばり具合を表すものは何ですか。
	\item 医者が患者を慎重に見続けるだけで治療を始めないことで、本来救えた命を失う可能性がある状況は、統計的過誤のどちらを増大させるリスクがありますか。
	\item 誤って差があると主張する過誤（質問1）の確率と、本当の差を見逃す過誤（質問2）の確率が、同時にゼロにできない関係にあることを何の関係と呼びますか。
	\item 統計的検定において、母集団の平均値の差に関する仮説を検証する際などに用いられる代表的な検定手法は何ですか。
	\item 統計的検定における二種類の過誤（質問1と質問2）を定式化し、合理的な判断を導くための体系的な手法は何ですか。
	\item マーケティングのA/Bテストなどにおいて、データがカテゴリーや頻度（割合）である場合に、二つのグループ間の関連性や差を検証するためによく用いられる検定手法は何ですか。
	\item 常に「もうすぐ不況になる」と予測し続ける経済評論家が、結果として追求し、最大化しようとしている統計的指標は何ですか。
\end{enumerate}

\subsubsection*{解答一覧}
1. $\alpha$エラー, 2. $\beta$エラー, 3. 検出力, 4. 有意水準, 5. 帰無仮説, 6. 統計的に有意, 7. 第一種の過誤, 8. 最強力検定, 9. 標準偏差, 10. 第二種の過誤, 11. トレードオフ, 12. $t$検定, 13. 統計的検定, 14. $\chi^2$検定, 15. 検出力

\section{参考文献}
\begin{thebibliography}{9}
	\bibitem{Vickers}
	What is a p-value anyway $?$ - Vickers, Andrew J.
	\bibitem{toukei_saikyou}
	Statistics is the most powerful discipline (Practical Edition) - Kei Nishiuci
\end{thebibliography}

\end{document}